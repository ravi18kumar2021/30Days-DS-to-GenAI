{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsxbfY+w6lA3V5wHF7pIP5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravi18kumar2021/30Days-DS-to-GenAI/blob/main/Day05/Interview_QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ❓ Interview Questions"
      ],
      "metadata": {
        "id": "_21TUFsnwqqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is Precision vs Recall?**"
      ],
      "metadata": {
        "id": "FaGmoetIwzOl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Precision measures how many positive predicted are actually positive.\n",
        "\n",
        "$Precision = \\frac{TP}{TP + FP}$\n",
        "\n",
        "Whereas, Recall measure how many actual positive were correctly identified.\n",
        "$Recall = \\frac{TP}{TP + FN}$\n",
        "\n",
        "**Note:** Use Precision when False Positives are costly (eg. spam detection). Use Recall when False Negatives are costly (eg. cancer detection)."
      ],
      "metadata": {
        "id": "1BaZpe9swzLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. What is ROC-AUC?**"
      ],
      "metadata": {
        "id": "PEi9v9wrwzIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** ROC stands for Receiver Operating Characteristic curve. It plots True positive rate (Recall) vs False Positive Rate (FPR) at various thresholds.\n",
        "\n",
        "AUC = Area Under Curve\n",
        "\n",
        "When AUC close to 1, then it means model performs excellent. And when AUC is near 0.5, then model doesn't perform better than normal guessing."
      ],
      "metadata": {
        "id": "HboHfv1HwzFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. How do you handle imbalanced datasets?**\n"
      ],
      "metadata": {
        "id": "ePm9paq-wzCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** There are several techniques available:\n",
        "\n",
        "1. Data-level methods\n",
        "- Resampling:\n",
        "  - Oversampling minority class\n",
        "  - Undersampling majority class\n",
        "- Stratifies sampling during train-test split\n",
        "\n",
        "2. Model-level methods\n",
        "- Use class weights\n",
        "- Choose metrics like F1-score, ROC-AUC"
      ],
      "metadata": {
        "id": "B60h1mRI-Xjt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. What’s the purpose of stratified split?**\n"
      ],
      "metadata": {
        "id": "1f4OYWwYCyrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** This method ensures that the class distribution is preserved in both train and test sets.\n",
        "- It prevents biased evaluation when working with imbalanced dataset\n",
        "- It is especially important in classification problems."
      ],
      "metadata": {
        "id": "RSw0eNObC3XP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Difference between Logistic Regression and SVM?**"
      ],
      "metadata": {
        "id": "sbtK81gWDY32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:**\n",
        "\n",
        "|Feature|Logistic Regression|Support Vector Machine|\n",
        "|-------|-------------------|----------------------|\n",
        "|Output|Probabilities (via sigmoid)|Class label (via margin separation)|\n",
        "|Decision Boundary|Linear (can be extended)|Linear or Non-linear (via kernels)|\n",
        "|Interpretability|High (coefficients explain features)|Low|\n",
        "|Loss Function|Log Loss|Hinge Loss|\n",
        "|Best Used|When we want probabilities + interpretability|When we want strong boundary separation|"
      ],
      "metadata": {
        "id": "3BdgUsziDcgq"
      }
    }
  ]
}