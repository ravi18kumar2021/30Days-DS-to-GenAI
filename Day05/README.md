# ğŸ“… Day 5: Supervised ML â€“ Classification

## âœ… Topics Covered
- Binary classification overview
- Logistic Regression intuition and implementation
- Sigmoid function and decision boundaries
- Evaluation metrics:
  - Confusion Matrix
  - Accuracy, Precision, Recall, F1 Score
- Handling imbalanced data (intro)
- Model training with Scikit-learn

---

## ğŸ›  Tools Used
- Python 3.x
- NumPy, Pandas
- Scikit-learn
- Google Colab / Jupyter Notebook

---

## ğŸ’¡ Mini Project: Diabetes Prediction

### ğŸ“ Dataset
- **Source:** PIMA Indian Diabetes Dataset
- **Features:** Glucose, BMI, Age, Pregnancies, BloodPressure, etc.
- **Target:** `Outcome` (0 = no diabetes, 1 = diabetes)

---

## ğŸ” Key Tasks

### 1ï¸âƒ£ Data Preparation
- Split data into training and test sets (stratified)
- Standardized features using `StandardScaler`

### 2ï¸âƒ£ Model Building
- Trained **Logistic Regression** using Scikit-learn (`LogisticRegression`)
- Increased `max_iter` to ensure convergence (in case data is not scaled)

### 3ï¸âƒ£ Evaluation Metrics
- Predicted labels and probabilities
- Calculated:
  - Accuracy
  - Precision
  - Recall
  - F1 Score
  - ROC-AUC Score
- Confusion matrix to inspect model performance

---

## âœ… Results Snapshot
| Metric     | Value   |
|------------|---------|
| Accuracy   | ~70â€“73% |
| Precision  | ~60â€“63% |
| Recall     | ~62â€“65% |
| F1 Score   | ~60â€“65% |
| AUC Score  | ~78â€“82% |

---

## ğŸ”§ Learning Outcomes
- Understood how logistic regression classifies binary outcomes
- Learned how to evaluate model effectiveness beyond accuracy
- Developed workflow for building and testing a classification model
- Gained awareness of convergence issues and data scaling

---

## ğŸ”„ To Improve Later (After Day 8)
- Visualize confusion matrix using `Seaborn`
- Plot ROC curve
- Explore model interpretability using feature coefficients
